library(shiny); runApp('C:/Users/joshg/Desktop/collarProcessingGit/app/MigrationMapperv1.3.r')
runApp('C:/Users/joshg/Desktop/collarProcessingGit/app/MigrationMapperv1.3.r')
runApp('MigrationMapperv1.3.r')
runApp('C:/Users/joshg/Desktop/collarProcessingGit/app/MigrationMapperv1.3.r')
runApp('C:/Users/joshg/Desktop/collarProcessingGit/app/MigrationMapperv1.3.r')
runApp('C:/Users/joshg/Desktop/collarProcessingGit/app/MigrationMapperv1.3.r')
migtime
runApp('C:/Users/joshg/Desktop/collarProcessingGit/app/MigrationMapperv1.3.r')
runApp('C:/Users/joshg/Desktop/collarProcessingGit/app/MigrationMapperv1.3.r')
runApp('C:/Users/joshg/Desktop/collarProcessingGit/app/MigrationMapperv1.3.r')
runApp('C:/Users/joshg/Desktop/collarProcessingGit/app/MigrationMapperv1.3.r')
runApp('C:/Users/joshg/Desktop/collarProcessingGit/app/MigrationMapperv1.3.r')
migtime
library(shiny); runApp('C:/Users/joshg/Desktop/collarProcessingGit/app/MigrationMapperv1.3.r')
runApp('MigrationMapperv1.3.r')
runApp('C:/Users/joshg/Desktop/collarProcessingGit/app/MigrationMapperv1.3.r')
runApp('C:/Users/joshg/Desktop/collarProcessingGit/app/MigrationMapperv1.3.r')
runApp('C:/Users/joshg/Desktop/collarProcessingGit/app/MigrationMapperv1.3.r')
library(shiny); runApp('C:/Users/joshg/Desktop/collarProcessingGit/app/MigrationMapperv1.3.r')
library(raster)
# use 1 km species stacks
# newNames<-names(oneKmStack)
# newNames<-strsplit(newNames,'_v1')
# newNames<- unlist(newNames)[2*(1:length(names(oneKmStack)))-1]
# names(oneKmStack)<-newNames
# saveRDS(oneKmStack,'D:\\GIS\\data\\usa\\GAPSPECIES2018\\oneKmAllStacked.rds')
# print('done')
#
# saveRDS(fiveKmStack,'D:\\GIS\\data\\usa\\GAPSPECIES2018\\fiveKmAllStacked.rds')
# # use 5 km species stacks
# # gott stack em..
# fileList <- list.files('D:\\GIS\\data\\usa\\GAPSPECIES2018\\GAP_CONUS_2001_5km', pattern = "*.tif$", full.names = T)
# fiveKmStack<-readAll(stack(fileList))
# newNames<-names(fiveKmStack)
# newNames<-strsplit(newNames,'_v1')
# newNames<- unlist(newNames)[2*(1:length(names(fiveKmStack)))-1]
# names(fiveKmStack)<-newNames
#
# saveRDS(fiveKmStack,'D:\\GIS\\data\\usa\\GAPSPECIES2018\\fiveKmAllStacked.rds')
# oneKmStack<-readRDS('D:\\GIS\\data\\usa\\GAPSPECIES2018\\oneKmAllStacked.rds')
# spcStack<-readRDS('D:\\GIS\\data\\usa\\GAPSPECIES2018\\fiveKmAllStacked.rds')
spcStack<-readRDS(file.choose())
# atTab<-read.csv('D:\\GIS\\projects\\rockyMountainResearchStation\\usaSpeciesPadus\\data\\tablesSummarized\\gapSpeciesSummaries082319.csv',stringsAsFactors = F)
atTab<-read.csv(file.choose(),stringsAsFactors = F)
atTab$gap_12_prc<-atTab$gap_1_prc+atTab$gap_2_prc
# representation priority
atTab$repPri<-1/atTab$gap_12_prc
atTab$repPriLog<-1/log10(atTab$gap_12_prc)
# rarity weighting
atTab$rarPri<-1/(atTab$total_area_1)
atTab$rarPriLog<-1/(log10(atTab$total_area_1))
# rarity and representation
atTab$repRar<-atTab$repPri*atTab$rarPri
atTab$repRarLog<-atTab$repPri*atTab$rarPriLog
repPriRich<-raster('C:\\Users\\joshg\\Desktop\\rarityWeightedRichness\\data\\richness\\repPriRich.tif')
repPriLogRich<-raster('C:\\Users\\joshg\\Desktop\\rarityWeightedRichness\\data\\richness\\repPriLogRich.tif')
rarPriRich<-raster('C:\\Users\\joshg\\Desktop\\rarityWeightedRichness\\data\\richness\\rarPriRich.tif')
rarPriLogRich<-raster('C:\\Users\\joshg\\Desktop\\rarityWeightedRichness\\data\\richness\\rarPriLogRich.tif')
repRarRich<-raster('C:\\Users\\joshg\\Desktop\\rarityWeightedRichness\\data\\richness\\repRarRich.tif')
repRarLogRich<-raster('C:\\Users\\joshg\\Desktop\\rarityWeightedRichness\\data\\richness\\repRarLogRich.tif')
repPriStack<-readRDS('C:\\Users\\joshg\\Desktop\\rarityWeightedRichness\\data\\richness\\repPriStack.rds')
repPriLogStack<-readRDS('C:\\Users\\joshg\\Desktop\\rarityWeightedRichness\\data\\richness\\repPriLogStack.rds')
rarPriStack<-readRDS('C:\\Users\\joshg\\Desktop\\rarityWeightedRichness\\data\\richness\\rarPriStack.rds')
rarPriLogStack<-readRDS('C:\\Users\\joshg\\Desktop\\rarityWeightedRichness\\data\\richness\\rarPriLogStack.rds')
repRarStack<-readRDS('C:\\Users\\joshg\\Desktop\\rarityWeightedRichness\\data\\richness\\repRarStack.rds')
repRarLogStack<-readRDS('C:\\Users\\joshg\\Desktop\\rarityWeightedRichness\\data\\richness\\repRarLogStack.rds')
library(raster)
# use 1 km species stacks
# newNames<-names(oneKmStack)
# newNames<-strsplit(newNames,'_v1')
# newNames<- unlist(newNames)[2*(1:length(names(oneKmStack)))-1]
# names(oneKmStack)<-newNames
# saveRDS(oneKmStack,'D:\\GIS\\data\\usa\\GAPSPECIES2018\\oneKmAllStacked.rds')
# print('done')
#
# saveRDS(fiveKmStack,'D:\\GIS\\data\\usa\\GAPSPECIES2018\\fiveKmAllStacked.rds')
# # use 5 km species stacks
# # gott stack em..
# fileList <- list.files('D:\\GIS\\data\\usa\\GAPSPECIES2018\\GAP_CONUS_2001_5km', pattern = "*.tif$", full.names = T)
# fiveKmStack<-readAll(stack(fileList))
# newNames<-names(fiveKmStack)
# newNames<-strsplit(newNames,'_v1')
# newNames<- unlist(newNames)[2*(1:length(names(fiveKmStack)))-1]
# names(fiveKmStack)<-newNames
#
# saveRDS(fiveKmStack,'D:\\GIS\\data\\usa\\GAPSPECIES2018\\fiveKmAllStacked.rds')
# oneKmStack<-readRDS('D:\\GIS\\data\\usa\\GAPSPECIES2018\\oneKmAllStacked.rds')
# spcStack<-readRDS('D:\\GIS\\data\\usa\\GAPSPECIES2018\\fiveKmAllStacked.rds')
# atTab<-read.csv('D:\\GIS\\projects\\rockyMountainResearchStation\\usaSpeciesPadus\\data\\tablesSummarized\\gapSpeciesSummaries082319.csv',stringsAsFactors = F)
atTab<-read.csv(file.choose(),stringsAsFactors = F)
atTab$gap_12_prc<-atTab$gap_1_prc+atTab$gap_2_prc
# representation priority
atTab$repPri<-1/atTab$gap_12_prc
atTab$repPriLog<-1/log10(atTab$gap_12_prc)
# rarity weighting
atTab$rarPri<-1/(atTab$total_area_1)
atTab$rarPriLog<-1/(log10(atTab$total_area_1))
# rarity and representation
atTab$repRar<-atTab$repPri*atTab$rarPri
atTab$repRarLog<-atTab$repPri*atTab$rarPriLog
plot(atTab$rarPri,atTab$rarPriLog)
hist(atTab$rarPri)
hist(atTab$rarPriLog)
hist(atTab$rarPri)
hist(atTab$rarPriLog)
plot(atTab$repPri,atTab$repPriLog)
plot(atTab$repPri,atTab$repPriLog)
repPriRich<-raster('C:\\Users\\joshg\\Desktop\\rarityWeightedRichness\\data\\richness\\repPriRich.tif')
repPriLogRich<-raster('C:\\Users\\joshg\\Desktop\\rarityWeightedRichness\\data\\richness\\repPriLogRich.tif')
rarPriRich<-raster('C:\\Users\\joshg\\Desktop\\rarityWeightedRichness\\data\\richness\\rarPriRich.tif')
rarPriLogRich<-raster('C:\\Users\\joshg\\Desktop\\rarityWeightedRichness\\data\\richness\\rarPriLogRich.tif')
repRarRich<-raster('C:\\Users\\joshg\\Desktop\\rarityWeightedRichness\\data\\richness\\repRarRich.tif')
repRarLogRich<-raster('C:\\Users\\joshg\\Desktop\\rarityWeightedRichness\\data\\richness\\repRarLogRich.tif')
hist(repPriLogRich@data@values)
repPriLogRich@data@values
plot(repPriLogRich)
plot(repPriRich)
write.csv(atTab,file.choose())
hist(repPriLogRich@data@values)
plot(atTab$rarPri,atTab$rarPriLog)
log10(5800)
1/log10(1)
log10(1)
install.packages()
snow
snowfall
sfinit
library('snow')
sfinit()
require(snowfall)
sfInit()
sfIsRunning()
install.packages("remoter")
R.version()
R.version
R.version
packages()
library('snowfall')
library('snow')
library(shiny); runApp('C:/Users/joshg/Desktop/collarProcessingGit/app/MigrationMapperv1.3.r')
runApp('C:/Users/joshg/Desktop/collarProcessingGit/app/MigrationMapperv1.3.r')
library(shiny); runApp('C:/Users/joshg/Desktop/collarProcessingGit/app/MigrationMapperv2.r')
library(shiny); runApp('C:/Users/joshg/Desktop/collarProcessingGit/app/MigrationMapperv2.r')
library(raster)
library(ncdf4)
library(sf)
library(fasterize)
library(rgeos)
library(ggplot2)
library("cowplot")
library(geosphere)
library(rgdal)
rootDir<-'C:\\Users\\joshg\\Desktop\\climateDownscaling\\'
modelRadius <- c(100,200,300,400,500)
# rootDir<-''
##############
## Load in the varios datasets we want to downscale
##############
# t40 <- raster(paste0(rootDir,'testData\\mtt40.tif'))
# t40 <- raster(paste0(rootDir,'testData\\t40Bengal.tif'))
# t40 <- rotate(t40)
t40 <- raster(paste0(rootDir,'dataFromSean/downscale.these/tmax40days_19812010.nc'))
t40 <- rotate(t40)
t35 <- raster(paste0(rootDir,'dataFromSean/downscale.these/tmax35days_19812010.nc'))
t35 <- rotate(t35)
t30 <- raster(paste0(rootDir,'dataFromSean/downscale.these/tmax30days_19812010.nc'))
t30 <- rotate(t30)
tmin0 <- raster(paste0(rootDir,'dataFromSean/downscale.these/tmin0days_19812010.nc'))
tmin0 <- rotate(tmin0)
fwi <- raster(paste0(rootDir,'dataFromSean/downscale.these/fwi19days_19812010.nc'))
fwi <- rotate(fwi)
## TMAX for predicting
# tmax <- raster(paste0(rootDir,'testData\\mttmax.tif'))
# tmax <- raster(paste0(rootDir,'testData\\tmaxBengal.tif'))
tmax <- raster(paste0(rootDir,'dataFromSean/TerraClimate.normals/tmax.1981.2010.tif'))
## also some elevation for predicting
# elev <- raster(paste0(rootDir,'testData\\mtelev.tif'))
# elev <- raster(paste0(rootDir,'testData\\elevBengal.tif'))
# elev <- raster(paste0(rootDir,'testData\\elevBengal.tif'))
elev <- raster(paste0(rootDir,'elevation/ETOPO1_Ice_g_geotiff.tif'))
## create analysis mask - snap tmax to t40 and match cell sizes
mask <- projectRaster(tmax, t40, method='bilinear')
## assign each 0.25 degree pixel a unique ID and create a dataframe with rach row/record representing a 0.35 degree pixel
cellIds <- Which(mask < 1000, cells=T)
trainingDataFrame <- as.data.frame(xyFromCell(mask, cell=cellIds))
trainingDataFrame$uid <- cellIds
trainingDataFrame$t40<-round(extract(t40, trainingDataFrame[, c('x','y')], method='bilinear'), 2)
trainingDataFrame$t35<-round(extract(t35, trainingDataFrame[, c('x','y')], method='bilinear'), 2)
trainingDataFrame$t30<-round(extract(t30, trainingDataFrame[, c('x','y')], method='bilinear'), 2)
trainingDataFrame$tmin0<-round(extract(tmin0, trainingDataFrame[, c('x','y')], method='bilinear'), 2)
trainingDataFrame$fwi<-round(extract(fwi, trainingDataFrame[, c('x','y')], method='bilinear'), 2)
trainingDataFrame$tmax <- round(extract(tmax, trainingDataFrame[, c('x','y')], method='bilinear'), 2)
trainingDataFrame$elev <- round(extract(elev, trainingDataFrame[, c('x','y')], method='bilinear'), 2)
# Make a copy
# tempDf <- trainingDataFrame
# create a temp raster that represents the UIDs
rasterOfCellNums <- rasterFromXYZ(trainingDataFrame[,c('x', 'y', 'uid')])
# only predict those cells where tmax is less than 1000
cellIdsForPredict <- Which(tmax < 1000, cells=T)
# create a temp dataframe on which to add the predicted values
dfForPredicting <- as.data.frame(xyFromCell(tmax, cell=cellIdsForPredict))
# extract the predictor and response values and the uid
dfForPredicting$tmax <- round(extract(tmax, dfForPredicting[, c('x','y')], method='bilinear'), 2)
dfForPredicting$elev <- round(extract(elev, dfForPredicting[, c('x','y')], method='bilinear'), 2)
dfForPredicting$t40 <- round(extract(t40, dfForPredicting[, c('x','y')], method='bilinear'), 2)
dfForPredicting$t35 <- round(extract(t35, dfForPredicting[, c('x','y')], method='bilinear'), 2)
dfForPredicting$t30 <- round(extract(t30, dfForPredicting[, c('x','y')], method='bilinear'), 2)
dfForPredicting$tmin0 <- round(extract(tmin0, dfForPredicting[, c('x','y')], method='bilinear'), 2)
dfForPredicting$fwi <- round(extract(fwi, dfForPredicting[, c('x','y')], method='bilinear'), 2)
dfForPredicting$uid <- extract(rasterOfCellNums, dfForPredicting[, c('x','y')], method='simple')
# ----------
# there are many cells (127,954)in the terraclimate data that don't overlap the T40 etc datasets
# for those we need to assign the nearest UID value from the raster of cell numbers
# nonOverlapCells<-which(is.na(dfForPredicting$uid))
# length(nonOverlapCells)
# for(i in 1:length(nonOverlapCells)){
# 	print(i)
# 	thisCellToFill<-nonOverlapCells[i]
# 	searchCenter <- SpatialPoints(dfForPredicting[thisCellToFill,c('x', 'y')], proj4string=crs(t40))
# 	# 4 degree radius search
# 	searchBuffer <- gBuffer(searchCenter, width = 4)
# 	extractedForSearch <- mask(rasterOfCellNums,searchBuffer)
# 	extractedForSearch <- data.frame(rasterToPoints(extractedForSearch))
# 	extractedForSearch$searchX<-dfForPredicting[thisCellToFill,c('x')]
# 	extractedForSearch$searchY<-dfForPredicting[thisCellToFill,c('y')]
# 	extractedForSearch$distancec<-distCosine(extractedForSearch[,c('searchX','searchY')], extractedForSearch[,c('x','y')])
# 	minRowc<-which(extractedForSearch$distancec==min(extractedForSearch$distancec))
# 	newUid<-extractedForSearch[minRowc,]$uid
# 	dfForPredicting[thisCellToFill,'uid']<-newUid
# }
# add some na values for the incoming predicted values
for(i in 1:length(modelRadius)){
thisRadius<-modelRadius[i]
dfForPredicting[,paste0('t40TmaxPred',thisRadius)]<- -99
dfForPredicting[,paste0('t40ElevPred',thisRadius)]<- -99
dfForPredicting[,paste0('t40TmaxElevPred',thisRadius)]<- -99
dfForPredicting[,paste0('t35TmaxPred',thisRadius)]<- -99
dfForPredicting[,paste0('t35ElevPred',thisRadius)]<- -99
dfForPredicting[,paste0('t35TmaxElevPred',thisRadius)]<- -99
dfForPredicting[,paste0('t30TmaxPred',thisRadius)]<- -99
dfForPredicting[,paste0('t30ElevPred',thisRadius)]<- -99
dfForPredicting[,paste0('t30TmaxElevPred',thisRadius)]<- -99
dfForPredicting[,paste0('tmin0TmaxPred',thisRadius)]<- -99
dfForPredicting[,paste0('tmin0ElevPred',thisRadius)]<- -99
dfForPredicting[,paste0('tmin0TmaxElevPred',thisRadius)]<- -99
dfForPredicting[,paste0('fwiTmaxPred',thisRadius)]<- -99
dfForPredicting[,paste0('fwiElevPred',thisRadius)]<- -99
dfForPredicting[,paste0('fwiTmaxElevPred',thisRadius)]<- -99
trainingDataFrame[,paste0('t40TmaxPred',thisRadius)]<- -99
trainingDataFrame[,paste0('t40ElevPred',thisRadius)]<- -99
trainingDataFrame[,paste0('t40TmaxElevPred',thisRadius)]<- -99
trainingDataFrame[,paste0('t35TmaxPred',thisRadius)]<- -99
trainingDataFrame[,paste0('t35ElevPred',thisRadius)]<- -99
trainingDataFrame[,paste0('t35TmaxElevPred',thisRadius)]<- -99
trainingDataFrame[,paste0('t30TmaxPred',thisRadius)]<- -99
trainingDataFrame[,paste0('t30ElevPred',thisRadius)]<- -99
trainingDataFrame[,paste0('t30TmaxElevPred',thisRadius)]<- -99
trainingDataFrame[,paste0('tmin0TmaxPred',thisRadius)]<- -99
trainingDataFrame[,paste0('tmin0ElevPred',thisRadius)]<- -99
trainingDataFrame[,paste0('tmin0TmaxElevPred',thisRadius)]<- -99
trainingDataFrame[,paste0('fwiTmaxPred',thisRadius)]<- -99
trainingDataFrame[,paste0('fwiElevPred',thisRadius)]<- -99
trainingDataFrame[,paste0('fwiTmaxElevPred',thisRadius)]<- -99
}
# #  -------------------------------
# # just for some quick verification
# # trainingDataFrame row 128053 has a t40 value of 21.6
# trainingDataFrame[128053,]
# # this equals uid of 290414
# # viewing these rows in the df where we'll predict verifies this 21.6 value
# # and also shows all the unique elevation and tmax values for these rows (cells)
# dfForPredicting[which(dfForPredicting$uid==290414),]
# !!!!!!!!!!!!!!! FWI AND TMIN HAVE VALUES OVER 365
# !!!!!!!!!!!!!!! FORCING THESE BACK TO 365 FOR NOW
trainingDataFrame[which(dfForPredicting$fwi>365),'fwi']<-365
dfForPredicting[which(dfForPredicting$fwi>365),'fwi']<-365
trainingDataFrame[which(dfForPredicting$tmin0>365),'tmin0']<-365
dfForPredicting[which(dfForPredicting$tmin0>365),'tmin0']<-365
trainingDataFrame[which(dfForPredicting$tmin0>365),'tmin0']<-365
trainingDataFrame[which(dfForPredicting$tmin0>365),'tmin0']<-365
saveRDS(trainingDataFrame,file.choose())
saveRDS(dfForPredicting,file.choose())
f<-readRDS(file.choose())
dim(f)
library(shiny); runApp('C:/Users/joshg/Desktop/collarProcessingGit/app/MigrationMapperv2.1.r')
runApp('C:/Users/joshg/Desktop/collarProcessingGit/app/MigrationMapperv2.1.r')
selectedYearStartDate
library(shiny); runApp('C:/Users/joshg/Desktop/collarProcessingGit/app/MigrationMapperv2.1.r')
runApp('C:/Users/joshg/Desktop/collarProcessingGit/app/MigrationMapperv2.1.r')
library(shiny); runApp('C:/Users/joshg/Desktop/collarProcessingGit/app/MigrationMapperv2.2.r')
runApp('C:/Users/joshg/Desktop/collarProcessingGit/app/MigrationMapperv2.2.r')
runApp('C:/Users/joshg/Desktop/collarProcessingGit/app/MigrationMapperv2.2.r')
runApp('C:/Users/joshg/Desktop/collarProcessingGit/app/MigrationMapperv2.2.r')
install.packages('rgdal')
install.packages("rgdal")
library(shiny); runApp('C:/Users/joshg/Desktop/collarProcessingGit/app/MigrationMapperv2.2.r')
dat<-read.csv(file.choose(),stringsAsFactors = F)
suM(dat[which(dat$blm_idx_ak_p95>0)])
sum(dat[which(dat$blm_idx_ak_p95>0)])
sum(dat[which(dat$blm_idx_ak_p95>0),'blm_idx_ak_p95'])
library(shiny); runApp('C:/Users/joshg/Desktop/mapp/MAPP.R')
runApp('C:/Users/joshg/Desktop/mapp/MAPP.R')
runApp('C:/Users/joshg/Desktop/mapp/MAPP.R')
runApp('C:/Users/joshg/Desktop/mapp/MAPP.R')
runApp('C:/Users/joshg/Desktop/mapp/MAPP.R')
runApp('C:/Users/joshg/Desktop/mapp/MAPP.R')
runApp('C:/Users/joshg/Desktop/mapp/MAPP.R')
app1_init<-function(input,output,session){
input<<-input
output<<-output
session<<-session
progressTracker<<-list()
observeEvent(input$maxSpeedSelector,{
maxSpeedParameter<<-(input$maxSpeedSelector*1000)/3600
},ignoreInit=TRUE)
observeEvent(input$mortDistance,{
mortDistance<<-input$mortDistance
},ignoreInit=TRUE)
observeEvent(input$mortTime,{
mortTime<<-input$mortTime
},ignoreInit=TRUE)
observeEvent(input$getStartedButton, {
toggleModal(session,'welcomeModal',toggle='close')
},ignoreInit=TRUE)
toggleModal(session,'welcomeModal',toggle='open')
observeEvent(input$parametersButton, {
toggleModal(session,'configModal',toggle='open')
},ignoreInit=TRUE)
observeEvent(input$chooseDirButton, {
dataFolder<<-choose.dir()
availableShapefiles <<- list.files(dataFolder, pattern = '.shp$')
if (length(availableShapefiles) == 0) {
modalMessager(
"Folder Selection Error",
"No valid shapefile are present in this directory. Please check the
directory and try again"
)
return
}
availableShapefiles <- append("", availableShapefiles)
##--------------------------------make a label showing selected folder
output$selectedDirectoryLabel <- renderUI({
p(paste("You successfully imported ", dataFolder, sep = ""))
})
##--------------------------------render the dropdown for available shapes
output$selectedShapefileHeaderLabel <- renderUI({
strong('(2) Choose shapefile(s) from the selected data directory')
})
output$fileUploadSelectorHolder <- renderUI({
selectInput(
"fileUploadSelector",
"",
availableShapefiles,
selected = NULL,
multiple = TRUE
)
})
##------------------ start file import
output$fileUploadExecute<-renderUI({
actionButton('fileUploadExecute','Begin File Import')
})
})
observeEvent(input$fileUploadExecute, {
if(exists('importedDatasetMaster')){
toggleModal(session,'moreDataModal',toggle='toggle')
return()
}
if(is.null(input$fileUploadSelector)){
modalMessager('Error','You need to select a shapefile to continue import')
return()
}
prepareFileImport()
})
dtvRunning<<-FALSE;
observeEvent(input$processDatesButton,{
if(!dtvRunning){
dateTimeValidator()
}
})
}
runApp('C:/Users/joshg/Desktop/mapp/app1_dataCleaning/app1.R')
runApp('C:/Users/joshg/Desktop/mapp/app1_dataCleaning/app1.R')
runApp('C:/Users/joshg/Desktop/mapp/app1_dataCleaning/app1.R')
runApp('C:/Users/joshg/Desktop/mapp/app1_dataCleaning/app1.R')
library(shiny); runApp('C:/Users/joshg/Desktop/mapp/app1_dataCleaning/app1.R')
install.packages("shiny")
install.packages("Rcpp", dependencies = T)
install.packages("shiny")
install.packages('rtoots')
install.packages('rtools')
install.packages('Rtools')
R.version
library(shiny); runApp('C:/Users/joshg/Desktop/mapp/app1_dataCleaning/app1.R')
library(shiny); runApp('C:/Users/joshg/Desktop/mapp/app2_sequencing/app2.r')
runApp('C:/Users/joshg/Desktop/mapp/app2_sequencing/app2.r')
runApp('C:/Users/joshg/Desktop/mapp/app2_sequencing/app2.r')
runApp('C:/Users/joshg/Desktop/mapp/app2_sequencing/app2.r')
runApp('C:/Users/joshg/Desktop/mapp/app2_sequencing/app2.r')
runApp('C:/Users/joshg/Desktop/mapp/app2_sequencing/app2.r')
runApp('C:/Users/joshg/Desktop/mapp/app2_sequencing/app2.r')
runApp('C:/Users/joshg/Desktop/mapp/app2_sequencing/app2.r')
library(shiny); runApp('C:/Users/joshg/Desktop/mapp/app1_dataCleaning/app1.R')
runApp('C:/Users/joshg/Desktop/mapp/app1_dataCleaning/app1.R')
runApp('C:/Users/joshg/Desktop/mapp/app1_dataCleaning/app1.R')
runApp('C:/Users/joshg/Desktop/mapp/app2_sequencing/app2.r')
currentIndividual
tempD<-importedDatasetMaster@data[which(importedDatasetMaster@data$id_yr==currentIndividual),]
dim(tempD)
min(tempD@newMasterDAte)
min(tempD@newMasterDate)
tempD$newMasterDate
min(tempD$newMasterDate)
max(tempD$newMasterDate)
tempD<-importedDatasetMaster@data[which(importedDatasetMaster@data$id_yr==currentIndividual),]
currentIndividual
tempD<-importedDatasetMaster@data[which(importedDatasetMaster@data$newUid==1),]
max(tempD$newMasterDate)
min(tempD$newMasterDate)
runApp('C:/Users/joshg/Desktop/mapp/app2_sequencing/app2.r')
library(raster)
araster<-raster(file.choose())
objs <- ls(pos = ".GlobalEnv")
araster<-raster(file.choose())
plot(araster)
tempD<-importedDatasetMaster@data[which(importedDatasetMaster@data$newUid==1),]
jj<-extract(tempD,araster)
tempD<-importedDatasetMaster[which(importedDatasetMaster@data$newUid==1),]
jj<-extract(tempD,araster)
?extract
jj<-extract(araster,tempD)
jj
araster
araster<-raster(file.choose())
araster
araster[araster < 0] <- NA
araster
writeRaster(araster,file.choose())
?saveRDS()
saveRDS(araster,file.choose())
library(raster)
ras<-raster(file.choose())
writeRaster(ras,file.choose(),options="COMPRESS=LZW")
library(shiny); runApp('C:/Users/joshg/Desktop/mapp/app2_sequencing/app2.r')
unique(importedDatasetMaster@data$newUid)
j<-importedDatasetMaster[which(importedDatasetMaster@data$newUid=24),]
j<-importedDatasetMaster[which(importedDatasetMaster@data$newUid==24),]
j
plot(j)
j<-importedDatasetMaster[which(importedDatasetMaster@data$newUid==23),]
plot(j)
ls()
ras
ras<-raster(file.choose())
plot(ras)
ras
x<-extract(ras,j)
x
plot(j)
plot(x)
abline
plot(x,type='line')
plot(x)
library(shiny); runApp('C:/Users/joshg/Desktop/mapp/app2_sequencing/app2.r')
runApp('C:/Users/joshg/Desktop/mapp/app1_dataCleaning/app1.R')
runApp('C:/Users/joshg/Desktop/mapp/app1_dataCleaning/app1.R')
runApp('C:/Users/joshg/Desktop/mapp/app1_dataCleaning/app1.R')
library(shiny); runApp('C:/Users/joshg/Desktop/mapp/app1_dataCleaning/app1.R')
runApp('C:/Users/joshg/Desktop/mapp/app1_dataCleaning/app1.R')
library(shiny); runApp('C:/Users/joshg/Desktop/mapp/app1_dataCleaning/app1.R')
hasMapRendered
runApp('C:/Users/joshg/Desktop/mapp/app1_dataCleaning/app1.R')
runApp('C:/Users/joshg/Desktop/mapp/app1_dataCleaning/app1.R')
runApp('C:/Users/joshg/Desktop/mapp/app2_sequencing/app2.r')
configOptions
tempDate<-format(configOptions$bioYearStartDate,'%m-%d')
?format
tempDate<-format(as.Date(configOptions$bioYearStartDate),'%m-%d')
tempDate
runApp('C:/Users/joshg/Desktop/mapp/app2_sequencing/app2.r')
runApp('C:/Users/joshg/Desktop/mapp/app2_sequencing/app2.r')
runApp('C:/Users/joshg/Desktop/mapp/app2_sequencing/app2.r')
runApp('C:/Users/joshg/Desktop/mapp/app3_sequenceWriting/app3.R')
theseSequencesPoints
theseSequencePoints
library(shiny); runApp('C:/Users/joshg/Desktop/mapp/app3_sequenceWriting/app3.R')
